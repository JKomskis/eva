core:
  location: "eva_datasets"
  sqlalchemy_database_uri: 'mysql+pymysql://root@localhost/eva_catalog'
  application: "eva"
  mode: "debug" #release

executor:
  # batch_mem_size configures the number of rows processed by the execution engine in one iteration
  # #rows = max(1, row_mem_size / batch_mem_size)
  batch_mem_size: 4000000 # 4mb

  # batch size used for gpu_operations
  gpu_batch_size: 1700

  gpus: {'130.207.125.60': [0]}
storage:
  engine: "src.storage.petastorm_storage_engine.PetastormStorageEngine"
  path_prefix: "/tmp"
  # https://petastorm.readthedocs.io/en/latest/api.html#module-petastorm.reader
  # petastorm: {'cache_type' : 'local-disk',
  #             'cache_location' : '.cache',
  #             'cache_size_limit' : 4000000000, #4gb
  #             'cache_row_size_estimate' : 512}

pyspark:
  property: {'spark.logConf': 'true',
             'spark.driver.memory': '4g',
             'spark.sql.execution.arrow.pyspark.enabled': 'true'}
  coalesce: 1


server:
  host: "0.0.0.0"
  port: 5432
  socket_timeout: 60
